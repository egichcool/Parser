{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(path):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(path)\n",
    "        print(f'Успешное подключение к базе по пути {path}')\n",
    "    except Error as e:\n",
    "        print(f'Ошибка {e}')\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        #print('Запрос успешно выполнен')\n",
    "    except Error as e:\n",
    "        print(f'Ошибка {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_connection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cb89b33aa793>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbase_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'DB/tester_with_searchwords.sqlite'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'create_connection' is not defined"
     ]
    }
   ],
   "source": [
    "base_name = 'DB/tester_with_searchwords.sqlite'\n",
    "connection = create_connection(base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_users_table = '''\n",
    "CREATE TABLE IF NOT EXISTS data (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    name TEXT NOT NULL,\n",
    "    annotation TEXT NOT NULL,\n",
    "    registration_number TEXT NOT NULL       \n",
    ");\n",
    "'''\n",
    "execute_query(connection, create_users_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_posts_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS keywords(\n",
    "  id INTEGER PRIMARY KEY AUTOINCREMENT, \n",
    "  work_registration_number TEXT NOT NULL, \n",
    "  keyword TEXT NOT NULL, \n",
    "  FOREIGN KEY (work_registration_number) REFERENCES data (registration_number)\n",
    ");\n",
    "\"\"\"\n",
    "execute_query(connection, create_posts_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_name == 'DB/tester_with_searchwords.sqlite':\n",
    "    create_key_search_table = '''\n",
    "    CREATE TABLE IF NOT EXISTS keysearch(\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        word TEXT NOT NULL,\n",
    "        work_registration_number TEXT NOT NULL,\n",
    "        FOREIGN KEY (work_registration_number) REFERENCES data (registration_number)\n",
    "    )\n",
    "    '''\n",
    "    create_keys_table = '''\n",
    "    CREATE TABLE IF NOT EXISTS allwords(\n",
    "        if INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        ДОДЕЛАТЬ\n",
    "    )\n",
    "    '''\n",
    "    execute_query(connection, create_key_search_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "\tid\n",
      "\tname\n",
      "\tannotation\n",
      "\tregistration_number\n",
      "\n",
      "keywords\n",
      "\tid\n",
      "\twork_registration_number\n",
      "\tkeyword\n",
      "\n",
      "keysearch\n",
      "\tid\n",
      "\tword\n",
      "\twork_registration_number\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "for table_name in tables:\n",
    "    if table_name[0] != 'sqlite_sequence':\n",
    "        table_name = table_name[0]\n",
    "        table = pd.read_sql_query(\"SELECT * from {} LIMIT 0\".format(table_name), connection)\n",
    "        print(table_name)\n",
    "        for col in table.columns:\n",
    "            print('\\t' + col)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2364675/2364675 [09:56<00:00, 3967.17it/s]\n",
      "100%|██████████| 16622/16622 [00:02<00:00, 7999.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from flashtext import KeywordProcessor\n",
    "import re\n",
    "\n",
    "\n",
    "def get_all_scrap_simbols():\n",
    "    with open('Data/trash_simbols.txt', 'r', encoding='UTF-8') as f:\n",
    "        trash_simbols = f.read()\n",
    "    return trash_simbols\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "with open('Data/predlogi.txt', 'r', encoding='utf-8') as f:\n",
    "    predlogi = f.readline()\n",
    "predlogi = predlogi.split(',')\n",
    "#predlogi.extend(get_all_scrap_simbols())\n",
    "\n",
    "#for ch in string.punctuation:\n",
    "#    predlogi.append(ch)\n",
    "\n",
    "punctuation_processor = KeywordProcessor()\n",
    "for word in predlogi:\n",
    "    punctuation_processor.add_keyword(word, ' ')\n",
    "\n",
    "\n",
    "with open('Data/nioktr_2021_all_months.json', 'r', encoding=\"utf-8\") as f:\n",
    "    file_len = len(f.readlines())\n",
    "file1 = open('Data/nioktr_2021_all_months.json', 'r', encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def get_rid_of_brackets(text):\n",
    "    bracket_pos_left = text.find('\"')\n",
    "    while bracket_pos_left != -1:\n",
    "        bracket_pos_right = text.find('\"', bracket_pos_left)\n",
    "        if bracket_pos_right == -1:\n",
    "            break\n",
    "        else:\n",
    "            text = text.replace('\"', '«', 1)\n",
    "            text = text.replace('\"', '»', 1)\n",
    "    return text\n",
    "\n",
    "\n",
    "def replase_punctuation(input):\n",
    "    replased = re.sub(get_all_scrap_simbols(), ' ', input)\n",
    "    return punctuation_processor.replace_keywords(replased)\n",
    "\n",
    "'''\n",
    "def has_numbers(input):\n",
    "    return any(char.isdigit() for char in input)\n",
    "'''\n",
    "\n",
    "def make_base():\n",
    "    works = []\n",
    "    keyword_flag = False\n",
    "    registration_flag = False\n",
    "    count = 0\n",
    "    #while True:\n",
    "    #for i in tqdm(range(500)):\n",
    "    #for i in tqdm(range(2364859)):            \n",
    "    for i in tqdm(range(file_len)):  \n",
    "        line = file1.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if \"registration_number\" in line:\n",
    "            registration_flag = True\n",
    "            if 'АААА' in line:\n",
    "                length = 33\n",
    "            else:\n",
    "                length = 24                \n",
    "            left = line.find('\"registration_number\"') + length\n",
    "            right = line.rfind('\"')            \n",
    "            registration_number = line[left:right]\n",
    "        if \"name\" in line and registration_flag == True:\n",
    "            left = line.find('\"name\": \"') + 9\n",
    "            right = line.rfind('\"')\n",
    "            s = get_rid_of_brackets(line[left:right])\n",
    "            new_s = ''   \n",
    "\n",
    "            #corrected = punctuation_processor.replace_keywords(s)\n",
    "            corrected = replase_punctuation(s)\n",
    "\n",
    "            for word in corrected.split():\n",
    "                if word.find(',') >= 0 or word.find(';') >= 0 or word.find('.') >= 0:\n",
    "                    word = word[:-1]\n",
    "                new_s = new_s + ' ' + morph.parse(word)[0].normal_form\n",
    "            works.append([new_s[1:], [], '', registration_number])\n",
    "            count += 1            \n",
    "        if ']' in line and keyword_flag == True:\n",
    "            works[count-1][1].extend(temp)\n",
    "            keyword_flag = False   \n",
    "            registration_flag = False\n",
    "        if keyword_flag == True and registration_flag == True:\n",
    "            left = line.find('\"')\n",
    "            right = line.rfind('\"')\n",
    "            s = get_rid_of_brackets(line[left+1:right]) \n",
    "            s = s.split(',')\n",
    "            for block in s:\n",
    "                #corrected = punctuation_processor.replace_keywords(block) \n",
    "                corrected = replase_punctuation(block)\n",
    "                new_s = ''\n",
    "                for word in corrected.split():\n",
    "                    new_s = new_s + ' ' + morph.parse(word)[0].normal_form\n",
    "                temp.append(new_s[1:])\n",
    "            #s = ' '.join(s)  \n",
    "        if \"keyword_list\" in line:\n",
    "            temp = []\n",
    "            keyword_flag = True\n",
    "        if \"annotation\" in line and registration_flag == True:            \n",
    "            left = line.find('\"annotation\": \"') + 15\n",
    "            right = line.rfind('\"')\n",
    "            s = get_rid_of_brackets(line[left:right])                          \n",
    "            #corrected = punctuation_processor.replace_keywords(s)   \n",
    "            corrected = replase_punctuation(s)\n",
    "            new_s = ''\n",
    "            for word in corrected.split():\n",
    "                if word.find(',') >= 0 or word.find(';') >= 0 or word.find('.') >= 0:\n",
    "                    word = word[:-1]\n",
    "                new_s = new_s + ' ' + morph.parse(word)[0].normal_form\n",
    "            works[-1][2] = new_s[1:]\n",
    "        #print(count)    \n",
    "    all_words = {}\n",
    "    for i, block in enumerate(tqdm(works)):\n",
    "        all_text = set(f'{block[0]} {block[2]} {\" \".join(block[1])}'.split())            \n",
    "        for word in all_text:\n",
    "            if len(word) > 2:\n",
    "                #if has_numbers(word):\n",
    "                value = all_words.get(word)\n",
    "                if value != None:\n",
    "                    value.append(block[3])\n",
    "                else:\n",
    "                    value = [block[3]]\n",
    "                all_words.update({word : value})\n",
    "\n",
    "        \n",
    "                               \n",
    "    return works, all_words\n",
    "\n",
    "result, all_words = make_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79571\n",
      "16622\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16622/16622 [01:27<00:00, 190.74it/s]\n",
      "100%|██████████| 79571/79571 [07:29<00:00, 177.17it/s] \n"
     ]
    }
   ],
   "source": [
    "insert_data = f\"\"\"\n",
    "INSERT INTO data (name, annotation, registration_number) VALUES \n",
    "\"\"\"    \n",
    "insert_keywords = f\"\"\"\n",
    "INSERT INTO keywords (work_registration_number, keyword)\n",
    "VALUES\n",
    "\"\"\"\n",
    "\n",
    "for i, block in enumerate(tqdm(result)):\n",
    "    insert_data += f'(\"{block[0]}\", \"{block[2]}\", \"{block[3]}\"),'\n",
    "    for keyword in block[1]:\n",
    "        insert_keywords += f'({block[3]}, \"{keyword}\"),'\n",
    "    if i % 8000 == 0:\n",
    "        insert_data = insert_data[:-1]\n",
    "        insert_keywords = insert_keywords[:-1]\n",
    "        execute_query(connection, insert_data)\n",
    "        execute_query(connection, insert_keywords)\n",
    "        \n",
    "        insert_data = f\"\"\"\n",
    "        INSERT INTO data (name, annotation, registration_number) VALUES \n",
    "        \"\"\"    \n",
    "        insert_keywords = f\"\"\"\n",
    "        INSERT INTO keywords (work_registration_number, keyword)\n",
    "        VALUES\n",
    "        \"\"\"\n",
    "\n",
    "if len(insert_data) > 82:\n",
    "    insert_data = insert_data[:-1]\n",
    "    insert_keywords = insert_keywords[:-1]\n",
    "    execute_query(connection, insert_data)\n",
    "    execute_query(connection, insert_keywords)\n",
    "\n",
    "\n",
    "insert_serachkeys = f'''\n",
    "INSERT INTO keysearch(word, work_registration_number)\n",
    "VALUES \n",
    "'''\n",
    "for i, (word, value) in enumerate(tqdm(all_words.items())):\n",
    "    for reg_number in value:\n",
    "        insert_serachkeys += f'(\"{word}\", \"{reg_number}\"),'        \n",
    "\n",
    "insert_serachkeys = insert_serachkeys[:-1]\n",
    "execute_query(connection, insert_serachkeys)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Заданное слово - нейтронный\n",
      "(None,)\n",
      "(None,)\n",
      "(None,)\n",
      "(None,)\n",
      "(None,)\n",
      "0.4649984836578369\n"
     ]
    }
   ],
   "source": [
    "tim = time.time()\n",
    "\n",
    "temp = '''\n",
    "SELECT id, name from data\n",
    "WHERE id < 10\n",
    "'''\n",
    "real_request = '''\n",
    "SELECT data.id, data.name, keywords.keyword\n",
    "FROM keywords INNER JOIN data on data.id = keywords.work_id\n",
    "WHERE keywords.keyword = 'дериватография'\n",
    "'''\n",
    "\n",
    "custom_request = '''\n",
    "SELECT data.id, data.name, keywords.keyword\n",
    "FROM keywords INNER JOIN data on data.id = keywords.work_id\n",
    "WHERE keywords.keyword = 'нанооптика'\n",
    "'''\n",
    "\n",
    "count_request = '''\n",
    "SELECT COUNT (DISTINCT data.name) AS \"Number of keywords\"\n",
    "FROM keywords INNER JOIN data on data.id = keywords.work_id\n",
    "WHERE keywords.keyword = \"нанооптика\"\n",
    "'''\n",
    "\n",
    "count_like_request = '''\n",
    "SELECT data.name\n",
    "FROM keywords LEFT OUTER JOIN data on data.registration_number = keywords.work_registration_number\n",
    "WHERE instr(keywords.keyword, 'нейтронный') OR instr(data.name, 'нейтронный') OR instr(data.annotation, 'нейтронный')\n",
    "LIMIT 5\n",
    "'''\n",
    "\n",
    "count_keys_request_2 = '''\n",
    "SELECT COUNT (DISTINCT word) FROM keysearch AS \"Number of keywords\"\n",
    "'''\n",
    "\n",
    "count_keys_request_1 = '''\n",
    "SELECT COUNT (word) FROM keysearch AS \"Number of keywords\"\n",
    "'''\n",
    "\n",
    "def get_all_works_by_word(word):\n",
    "    word = morph.parse(word)[0].normal_form\n",
    "    key_search_request = f'''\n",
    "    SELECT data.id, data.name\n",
    "    FROM keysearch INNER JOIN data ON data.registration_number = keysearch.work_registration_number\n",
    "    WHERE keysearch.word = '{word}'\n",
    "    ORDER BY data.id\n",
    "    LIMIT 5\n",
    "    '''\n",
    "    return key_search_request\n",
    "'''\n",
    "#WHERE keywords.keyword = 'нанооптика'\n",
    "#WHERE instr(keywords.keyword, 'нанооптик')\n",
    "\n",
    "'''\n",
    "\n",
    "get_all_keys_request = f'''\n",
    "SELECT data.name, keysearch.word\n",
    "FROM keysearch INNER JOIN data ON data.registration_number = keysearch.work_registration_number\n",
    "WHERE keysearch.word = 'дериватография'\n",
    "LIMIT 5\n",
    "'''\n",
    "\n",
    "key = 'нейтронный'\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#posts = cursor.execute(count_keys_request_2).fetchall()\n",
    "#posts = cursor.execute(count_keys_request_1).fetchall()\n",
    "#posts = cursor.execute(get_all_works_by_word(key)).fetchall()\n",
    "posts = cursor.execute(count_like_request).fetchall()\n",
    "\n",
    "print(f'Заданное слово - {key}')\n",
    "for post in posts:\n",
    "    print(post)\n",
    "\n",
    "print(time.time()-tim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
